<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><generator uri="https://jekyllrb.com/" version="4.3.4">Jekyll</generator><link href="https://xinleiren.github.io/feed.xml" rel="self" type="application/atom+xml"/><link href="https://xinleiren.github.io/" rel="alternate" type="text/html" hreflang="en"/><updated>2024-12-21T12:46:03+00:00</updated><id>https://xinleiren.github.io/feed.xml</id><title type="html">blank</title><subtitle>A simple, whitespace theme for academics. Based on [*folio](https://github.com/bogoli/-folio) design. </subtitle><entry><title type="html">文章列表</title><link href="https://xinleiren.github.io/blog/2024/blog-list/" rel="alternate" type="text/html" title="文章列表"/><published>2024-12-19T00:00:00+00:00</published><updated>2024-12-19T00:00:00+00:00</updated><id>https://xinleiren.github.io/blog/2024/blog-list</id><content type="html" xml:base="https://xinleiren.github.io/blog/2024/blog-list/"><![CDATA[<h2 id="论文笔记">论文笔记</h2> <h3 id="音频大模型">音频大模型</h3> <h3 id="音频信号处理">音频信号处理</h3> <ul> <li><a href="https://xinleiren.github.io/blog/2024/paper-yin/">【论文笔记之 YIN】YIN, a fundamental frequency estimator for speech and music</a></li> <li><a href="https://xinleiren.github.io/blog/2024/paper-pyin/">【论文笔记之 PYIN】PYIN, A Fundamental Frequency Estimator Using Probabilistic Threshold Distributions</a></li> </ul> <h3 id="语音增强分离">语音增强/分离</h3> <hr/> <h2 id="书籍笔记">书籍笔记</h2> <h3 id="digital-audio-effects2nd-ed">Digital Audio Effects(2nd ed.)</h3> <h3 id="digital-audio-resampling">Digital Audio Resampling</h3> <h3 id="speech-and-language-processing3rd-ed-draft">Speech and Language Processing(3rd ed. draft)</h3> <h3 id="the-scientist-and-engineers-guide-to-digital-signal-processing">The Scientist and Engineer’s Guide to Digital Signal Processing</h3> <hr/> <h2 id="笔者见解">笔者见解</h2> <h3 id="神经网络">神经网络</h3> <ul> <li><a href="https://xinleiren.github.io/blog/2024/causal-cnn/">谈谈音频信号处理中 CNN 的因果性</a></li> </ul> <h3 id="音频信号处理-1">音频信号处理</h3> <ul> <li><a href="https://xinleiren.github.io/blog/2024/yin/">基频提取算法-YIN</a></li> <li><a href="https://xinleiren.github.io/blog/2024/pyin/">基频提取算法-PYIN</a></li> </ul>]]></content><author><name></name></author><category term="blog-list"/><category term="音频信号处理"/><category term="语音增强"/><category term="神经网络"/><category term="音频大模型"/><summary type="html"><![CDATA[请读者先阅读该文章列表，以了解整个博客内容]]></summary></entry><entry><title type="html">谈谈音频信号处理中 CNN 的因果性</title><link href="https://xinleiren.github.io/blog/2024/causal-cnn/" rel="alternate" type="text/html" title="谈谈音频信号处理中 CNN 的因果性"/><published>2024-12-18T00:00:00+00:00</published><updated>2024-12-18T00:00:00+00:00</updated><id>https://xinleiren.github.io/blog/2024/causal-cnn</id><content type="html" xml:base="https://xinleiren.github.io/blog/2024/causal-cnn/"><![CDATA[<h2 id="1-引言">1. 引言</h2> <p>音频信号处理已经进入了神经网络时代，而 CNN 由于其强大的建模能力，已被广泛地应用在了各种音频信号处理网络中，像最近几届 DNS Challenge 的冠军所提出的网络均大量使用了 CNN。与图像处理不同，音频信号处理在大多数应用场景下都需要满足实时性要求，比如在线会议场景，直播场景等。满足实时性一般需要满足以下两个条件：算法是因果的且计算复杂度要低。本文主要讨论如何控制 CNN 网络的因果性，并不对其计算复杂度做过多讨论。</p> <p>从网络架构来说，以 CNN 为主的音频信号处理网络可以分为以下两大类：</p> <ul> <li>只包含卷积的 Encoder 架构</li> <li>即包含卷积又包含转置卷积的 Encoder-Decoder 架构</li> </ul> <p>本文对上述两种网络架构均进行了讨论，并进一步讨论了在实际 coding 过程中应该怎么做以及可能遇到的一些问题。</p> <h2 id="2-因果性">2. 因果性</h2> <p>在讨论之前，先简单介绍下系统的因果性。因果性是指：当一个系统当前时刻的输出只依赖于当前时刻的输入以及（或）过去时刻的输入时，该系统就是因果的。与之相对应的，当一个系统当前时刻的输出会依赖未来时刻的输入时，该系统就是非因果的。</p> <p>可见，在实时应用中，音频信号处理算法往往需要是因果的，以对当前时刻的输入信号作出及时的响应。</p> <h2 id="3-encoder-架构">3. Encoder 架构</h2> <p>Encoder 架构主要由卷积网络构成， 该节先从最简单的一层卷积网络开始讨论，接着拓展到多层卷积网络的情况。</p> <h3 id="31-一层卷积网络">3.1. 一层卷积网络</h3> <p>考虑一个只包含了一层二维卷积的网络，该二维卷积在时间维度上的参数为：kernel = 3，stride = 1。</p> <h4 id="311-网络的输入输出以及-label">3.1.1. 网络的输入，输出以及 label</h4> <p>假设此时输入给网络一个时长为 5 帧的音频信号，那么输出信号的时长应该为 5 - kernel + 1 = 5 - 3 + 1 = 3 帧，网络的输出比输入少了 2 帧（这 2 帧作为音频信号的上下文信息被网络消耗掉了）。那么问题来了：输出信号只有 3 帧，但 label 信号和输入信号一样都是 5 帧，输出信号的时长不等于 label 信号的时长，该怎么计算 loss 函数那？</p> <h4 id="312-决定网络的因果性">3.1.2. 决定网络的因果性</h4> <p>一个自然而然的想法就是：从 label 信号中选取 3 帧信号，保证 label 信号和输出信号的时长一样不就得了？没错，确实是这样做，而且正是该选取过程决定了卷积网络的因果性。</p> <p>以目前所讨论的这个网络来说，有 3 种选取方案，如图 1 所示。</p> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/causal_cnn/%E5%9B%BE1-480.webp 480w,/assets/img/causal_cnn/%E5%9B%BE1-800.webp 800w,/assets/img/causal_cnn/%E5%9B%BE1-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/assets/img/causal_cnn/%E5%9B%BE1.jpg" class="img-fluid rounded" width="100%" height="auto" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> <figcaption class="caption">图 1. 一层卷积网络因果性示例</figcaption> </figure> <ul> <li>图 1(a) 选取 label 信号中的最后 3 帧，这种选取方式确定了该网络是因果的。因为从图中可以看出当前时刻的输出帧只利用了当前时刻的输入帧以及历史的两帧信息；</li> <li>图 1(b) 选取 label 信号中最中间的 3 帧，这种选取方式确定了该网络是非因果的。因为从图中可以看出当前时刻的输出帧除了利用当前时刻的输入帧以及历史的 1 帧信息外，还使用了未来的 1 帧信息；</li> <li>图 1(c) 选取 label 信号中最前面的 3 帧，这种选取方式确定了该网络是非因果的。因为从图中可以看出当前时刻的输出帧除了利用当前时刻的输入帧外，还使用了未来的 2 帧信息；</li> </ul> <h4 id="313-补零操作">3.1.3. 补零操作</h4> <p>通过上述分析，相信读者已经熟悉该如何决定卷积网络的因果性，以及如何控制卷积网络的感受野。那么在实际 coding 的过程中，当拥有了输入数据和等时长的 label 数据之后，该怎么做，才能实现图 1 所示的 3 种方式那？主要有以下两种方法：</p> <ul> <li>丢 label 中的数据；</li> <li>给输入数据补零。</li> </ul> <p><strong>丢 label 中的数据</strong>：这种实现方式其实就是直接根据 3.1.2. 小节所分析的来做的。丢弃 label 信号中的前两帧信号得到的就是图 1(a) 所表示的；丢弃 label 信号中的第一帧和最后一帧信号得到的就是图 1(b) 所表示的；丢弃 label 信号中的最后两帧信号得到的就是图 1(c) 所表示的；</p> <p><strong>给输入数据补零</strong>：那么可不可以保持 label 数据不变，通过其他方法来实现那？当然可以！正所谓 “山不过来，我就过去”，既然要求 label 数据不变，那就变输入数据，给输入数据补零。相信读者在一些论文或者开源代码中也见过补零这种实现方式。补零相比上述实现方式有什么好处那？笔者考虑了一下，主要想出了以下两点说得过去的原因：</p> <ul> <li>为了不浪费数据。从上述分析可以看到，当卷积网络在时间维度上的 kernel 大于 1 时，网络的输出时长会比输入时长少 kernel - 1 帧。而 kernel 越大，网络的输出时长就越小。为了能将辛辛苦苦生成的训练数据全部用上，可以给输入信号补 kernel - 1 帧的零，这样就能使得网络的输出时长等于输入时长（有效的输入时长，即补零之前的时长）；</li> <li>为了和实时推理代码保持一致。 考虑一个实时应用会遇到的一个场景：假设某个音频处理算法运行在时频域（其 STFT 的窗长和帧长均为 20ms，帧移为 10ms），当算法接收到第一帧 10ms 信号的时候，为了做 STFT，往往需要在前面补一帧 10ms 的零，凑足 20ms。在因果卷积网络中补零的原因之一也是为了和这种场景保持一致。</li> </ul> <p>不同的补零方式会导致不同的因果关系，下面就详细说说，具体该怎么补零（读者可自行画图分析）：</p> <ul> <li>为了实现图 1(a)，可以在输入数据的最前面补两帧零；</li> <li>为了实现图 1(b)，可以在输入数据的最前面和最后面各补一帧零；</li> <li>为了实现图 1(c)，可以在输入数据的最后面补两帧零。</li> </ul> <h4 id="314-总结">3.1.4. 总结</h4> <p>从对一层卷积网络的分析过程来看，可以得到以下两个重要结论：</p> <ul> <li>从 label 信号中选取所需信号的过程决定了卷积网络的因果性和感受野；</li> <li>在具体 coding 的过程中，可以通过给输入数据补零来实现不同的因果关系。</li> </ul> <h3 id="32-多层卷积网络">3.2. 多层卷积网络</h3> <p>本节考虑包含了两层二维卷积的网络，且每层二维卷积在时间维度上的参数均为：kernel = 3，stride = 1。类似于图 1，现给出相应的两层 CNN 网络的因果性示例图，如图 2 所示。</p> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/causal_cnn/%E5%9B%BE2-480.webp 480w,/assets/img/causal_cnn/%E5%9B%BE2-800.webp 800w,/assets/img/causal_cnn/%E5%9B%BE2-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/assets/img/causal_cnn/%E5%9B%BE2.jpg" class="img-fluid rounded" width="100%" height="auto" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> <figcaption class="caption">图 2. 二层卷积网络因果性示例</figcaption> </figure> <p>需要注意的是，图 2 只给出了其中的三种输出结果，还有其余两种输出结果读者可自行分析。通过图 2 可以看出：</p> <ul> <li>图 2(a) 表示的是非因果网络，因为输出帧除了利用当前时刻的输入帧外，还使用了未来的 4 帧信息；</li> <li>图 2(b) 表示的是非因果网络，因为输出帧除了利用当前时刻的输入帧以及历史的 2 帧信息外，还使用了未来的 2 帧信息；</li> <li>图 2(c) 表示的是因果网络，因为输出帧只利用了当前时刻的输入帧以及历史的 4 帧信息。</li> </ul> <p>与 3.1. 节的分析过程一样，在实际 coding 过程中，该如何补零才能使得两层 CNN 网络实现图 2 中所示的因果性那？对于两层 CNN 网络来说，笔者能想到两种补零方式：输入层补零和逐层补零。下面就详细讨论下这两种方式，以及各自的优缺点。</p> <h4 id="321-输入层补零">3.2.1. 输入层补零</h4> <p>输入层补零其实就是把两层卷积网络等效于一层卷积网络。上述两层卷积网络可以等效于 kernel = 5，stride = 1 的一层卷积网络（只是从因果性和感受野角度来说是可以等效的）。从 3.1.3. 小节的分析可知：</p> <ul> <li>给输入数据的最后面补四帧零，可以实现图 2(a)；</li> <li>给输入数据的最前面和最后面各补两帧零，可以实现图 2(b)；</li> <li>给输入数据的最前面补四帧零，可以实现图 2(c)。</li> </ul> <p>也就是说输入层补零只在输入数据上补零，网络隐藏层不需要补零；下面要讨论的逐层补零除了在输入层补零外也在网络隐藏层补零。</p> <h4 id="322-逐层补零">3.2.2. 逐层补零</h4> <p>具体来说，逐层补零在实际 coding 的过程中：</p> <ul> <li>为了实现图 2(a)，可以在输入层和隐藏层的最后面分别补两帧零；</li> <li>为了实现图 2(b)，可以在输入层和隐藏层的最前面和最后面分别补一帧零；</li> <li>为了实现图 2(c)，可以在输入层和隐藏层的最前面分别补两帧零。</li> </ul> <p>逐层补零只考虑当前层。以图 2(a) 为例，输入层为 5 帧数据，为了使第一层 CNN 的输出也为 5 帧数据，并且保持只看当前帧和未来帧的因果性，需要给输入层的最后面补 kernel - 1 = 3 - 1 = 2 帧零。同样，为了使第二层 CNN 的输出也为 5 帧数据，并且保持只看当前帧和未来帧的因果性，需要给第一层 CNN 输出（隐藏层）的最后面补 kernel - 1 = 3 - 1 = 2 帧零。可以看出逐层补零保证每层 CNN 的输出时长都和 label 信号的时长保持一致。</p> <h4 id="323-两种补零方式对比">3.2.3. 两种补零方式对比</h4> <p>两种不同的补零方式可以说体现出了两种不同的思维方式。</p> <ul> <li>输入层补零：将多层 CNN 网络当成一个整体看待。先分析这个整体总共需要补多少零，需要怎么补，然后直接只在输入层操作就行；</li> <li>逐层补零：将多层 CNN 网络中的每一层当成单独的个体看待。根据当前层的 kernel 和 stride 求出当前层需要补多少零，根据整个网络要满足的因果性和感受野确定当前层的零该怎么补，然后在当前层直接操作就行。 逐层补零能保证每层的输出时长和输入时长（有效的输入时长，即补零之前的时长）一致，继而保证整个网络的输出时长和输入时长一致。当前层只需要干好它自己要干的事就好，不必考虑其他层。层与层之间的关系可以用一句古语来概括 “各人自扫门前雪，莫管他人瓦上霜”。</li> </ul> <p>下面再举个额外的例子，用以说明在实际 coding 过程中两种补零方式分别该怎么做。比如开发者要搭建一个两层 CNN 网络，且第一层 CNN 的参数配置为：kernel = 3，stride = 1，第二层 CNN 的参数配置为：kernel = 2，stride = 1。现在想要使这个网络的输出帧只能看未来一帧的输入信息。</p> <p><strong>输入层补零的做法</strong> 这个两层 CNN 网络可以等效为 kernel = 4，stride = 1 的一层 CNN 网络。因此，需要给输入数据补 kernel - 1 = 4 - 1 = 3 帧零。为了只看未来一帧的输入信息，需要将 2 帧零补在输入数据的最前面，1 帧零补在输入数据的最后面。</p> <p><strong>逐层补零的做法</strong> 可知输入层需要补 3 - 1 = 2 帧零，第一层 CNN 的输出需要补 2 - 1 = 1 帧零。接下来就是确定每层的零具体该怎么补。为了只看未来一帧的输入信息，可以有以下两种补零方案：</p> <ul> <li>输入层需要补的 2 帧零全补在最前面，且第一层 CNN 的输出需要补的 1 帧零补在最后面；这种方式使得第一层 CNN 没利用未来的输入信息，而第二层 CNN 利用了未来一帧的输入信息。</li> <li>输入层需要补的 2 帧零在最前面和最后面各补 1 帧，且第一层 CNN 的输出需要补的 1 帧零补在最前面；这种方式使得第一层 CNN 利用了未来一帧的输入信息，第二层 CNN 没有利用未来的输入信息。</li> </ul> <p>可以看到，在具体 coding 的时候，输入层补零这种方式实现方法唯一，而逐层补零这种方式有多种实现方法。</p> <h4 id="324-逐层补零需要注意的地方">3.2.4. 逐层补零需要注意的地方</h4> <p>假设一个这样的使用场景：1）模型是按照逐层补零的方式实现的因果模型；2）在验证模型效果的时候（即推理的时候）直接使用 load() 函数加载模型，而且按照线上运行的方式那样，每次给模型输入一帧数据，然后模型输出一帧数据；这个时候得到的输出结果很大概率上是不正确的。这是因为在训练模型的时候，模型的输入数据时长往往远远大于所补零的时长，除了输入数据中比较靠前的数据看到的历史信息是补的零之外，其余输入数据看到的历史信息基本都是有效的语音信息。而在推理过程中，每次只输入一帧数据，这导致输入的所有帧看到的历史信息都是补的零，而不是有效的语音信息。因此，输出结果大概率是不正确的。为了避免这种状况，1）只是为了验证模型效果的话，在推理的时候，可以增加模型的输入数据时长，而不是输入一帧数据；2）如果非要按照线上运行的方式那样，输入一帧数据输出一帧数据，那么就需要用 c/python 实现推理过程，与此同时需要维护好每层网络的输入 buffer。这是一项工作量较大的工程。 同样的场景，输入层补零的方式解决起来相对简单些，只需维护好输入层的 buffer 就行。</p> <h4 id="325-总结">3.2.5. 总结</h4> <p>本节以二层卷积网络为例，分析了多层网络如何通过补零来实现不同的因果性。在实际 coding 过程中主要有输入层补零和逐层补零两种方式，可根据需要选择适合的补零方式。</p> <h3 id="33-总结">3.3. 总结</h3> <p>对于 Encoder 架构而言，通过上述的分析可知，不管是一层卷积网络还是多层卷积网络，不管是输入层补零还是逐层补零，如果想要实现的网络是因果的，那么零应该全部补在最前面，如果想要实现的网络是非因果的，那么应该在最后面补零。在最前面补了几帧零，整个网络就使用了多少帧的历史信息。同理，在最后面补了几帧零，整个网络就使用了多少帧的未来信息。</p> <h2 id="4-encoder-decoder-架构">4. Encoder-Decoder 架构</h2> <p>Encoder-Decoder 是一种对称的网络结构。其中，Encoder 包含的是卷积网络，Decoder 包含的是转置（或称之为反转/逆）卷积网络。而且一般 Decoder 中每个转置卷积网络层和与之对应的 Encoder 中的卷积网络层的参数配置（kernel，stride……）是完全一样的。本节先简单回顾下转置卷积，然后分析一层卷积（转置卷积）网络的因果性，最后分析多层卷积（转置卷积）网络的因果性。</p> <h3 id="41-转置卷积">4.1. 转置卷积</h3> <p>与卷积相反，转置卷积会增加输入特征的维度。本节以 kernel = 3，stride = 1 的一层转置卷积网络为例进行说明。</p> <p>当给同等参数配置下的一层卷积网络输入 5 帧的音频信号时，它会输出 3 帧的音频信号。而如果将这 3 帧音频信号输入给一层转置卷积网络，那么将会输出 5 帧音频信号。图 3 展示了该转置卷积网络的计算过程。</p> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/causal_cnn/%E5%9B%BE3-480.webp 480w,/assets/img/causal_cnn/%E5%9B%BE3-800.webp 800w,/assets/img/causal_cnn/%E5%9B%BE3-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/assets/img/causal_cnn/%E5%9B%BE3.jpg" class="img-fluid rounded" width="100%" height="auto" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> <figcaption class="caption">图 3. 转置卷积网络计算过程示例</figcaption> </figure> <p>由于 kernel = 3，所以转置卷积网络每一帧输入所对应的输出都是 3 帧，将对应位置上的所有帧的输出相加得到转置卷积网络的最终输出。比如输出中的第二帧等于第一帧输出的第二个元素与第二帧输出的第一个元素之和，如图 3 中红圈所示。</p> <h3 id="42-一层卷积转置卷积网络">4.2. 一层卷积（转置卷积）网络</h3> <p>考虑一个 kernel = 3，stride = 1 的一层卷积（转置卷积）网络。假设网络的输入是时长为 5 帧的音频信号，那么经过卷积网络之后，时长变为 3 帧；接着，该 3 帧信号经过转置卷积网络之后，输出时长又变为 5 帧，与输入信号和 label 信号的时长是相等的。因此，此时可以正常计算 loss 函数。注意在此过程中，是没有额外的补零或者其他什么操作的。那么，此时网络的因果性和感受野是怎么样的那？可以通过图 4 分析一下整个计算过程。以输出的第 3 帧为例，可以看出计算该帧的过程中，除了使用输入的当前帧和历史两帧信息外，还使用了未来两帧信息。其余输出帧所使用的输入帧信息可以通过图 4 中的箭头走向分析得到。可以看到，此时网络是非因果网络，且使用了未来两帧的信息。</p> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/causal_cnn/%E5%9B%BE4-480.webp 480w,/assets/img/causal_cnn/%E5%9B%BE4-800.webp 800w,/assets/img/causal_cnn/%E5%9B%BE4-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/assets/img/causal_cnn/%E5%9B%BE4.jpg" class="img-fluid rounded" width="100%" height="auto" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> <figcaption class="caption">图 4. 一层卷积网络和转置卷积网络计算过程示例</figcaption> </figure> <h4 id="421-控制网络的因果性和感受野">4.2.1. 控制网络的因果性和感受野</h4> <p>那么，在具体 coding 过程中，该怎么做才能得到一个因果网络，并且使得该网络输出的有效时长还是 5 帧那？答案是输入数据补零，输出数据丢帧。图 5 展示了该计算过程。</p> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/causal_cnn/%E5%9B%BE5-480.webp 480w,/assets/img/causal_cnn/%E5%9B%BE5-800.webp 800w,/assets/img/causal_cnn/%E5%9B%BE5-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/assets/img/causal_cnn/%E5%9B%BE5.jpg" class="img-fluid rounded" width="100%" height="auto" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> <figcaption class="caption">图 5. 因果网络计算过程示例</figcaption> </figure> <p>在输入数据的最前面补两帧零之后，网络的总体输入变为了 7 帧，经过卷积和转置卷积之后，网络的输出依然是 7 帧。但是 label 数据时长和补零前的输入数据时长一样，都是 5 帧。此时，为了计算 loss 函数，需要从输出的 7 帧数据中丢弃 2 帧数据。该丢弃过程在决定网络的因果性和感受野方面也起到了重要作用。</p> <p>从图 5 中的箭头走向可以分析出，为了得到因果网络，只能丢弃输出数据中的最后两帧；同样可以分析出，为了得到非因果网络，且使用未来一帧的输入信息，只能丢弃输出数据中的第一帧和最后一帧；为了得到非因果网络，且使用未来两帧的输入信息，只能丢弃输出数据中最前面的两帧。</p> <h4 id="422-总结">4.2.2. 总结</h4> <p>本节介绍了如何通过给输入数据补零和丢弃输出数据来达到控制网络因果性和感受野的目的。本节给出的示例只是在输入数据的最前面补零，读者可按照同样的方法分析一下给输入数据最后面补零，或者最前面和最后面都补零会达到什么样的效果。</p> <h3 id="43-多层卷积转置卷积网络">4.3. 多层卷积（转置卷积）网络</h3> <p>可使用 3.2. 小节中的分析方法，对多层卷积（转置卷积）网络的因果性和感受野进行分析。即，可以把多层卷积（转置卷积）网络当成一个整体，只在输入数据和输出数据上做相应的补零或丢帧操作。也可以把网络中的每一层当成一个单独的个体，在每一层上做相应的操作，通过控制每一层的因果性和感受野来控制整个网络的因果性和感受野。具体分析过程，此处不在赘述。</p> <p>如果想要使 Encoder-Decoder 架构的网络在实际推理的过程中输入一帧数据输出一帧数据，那么，同样也会遇到 3.2.4. 小节所提到的问题。不管训练的时候采用的是哪种补零（或者丢帧）方式，都需要动手实现网络的推理过程，并维护好每一层的输入输出 buffer。</p> <h3 id="44-总结">4.4. 总结</h3> <p>对于 Encoder-Decoder 架构的网络来说，为了控制网络的因果性和感受野，在实际 coding 的过程中，可以通过给输入数据补零，并且丢弃输出数据中的帧来实现。</p> <h2 id="5-后记">5. 后记</h2> <p>前前后后历时一周，终于抽时间把这篇很久之前就想写的博客写完了。笔者是想到哪写到哪，有的点可能也没考虑到，如果读者感觉哪块写的不清楚或者有不同的意见和建议，欢迎提出，大家一起探讨。</p> <p>“先把书读厚，再把书读薄”。再次感谢读者阅读到此处，和笔者一起经历了 “先把书读厚” 的过程。下面献上一张图片，大家一起 “再把书读薄”。</p> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/causal_cnn/%E5%9B%BE6-480.webp 480w,/assets/img/causal_cnn/%E5%9B%BE6-800.webp 800w,/assets/img/causal_cnn/%E5%9B%BE6-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/assets/img/causal_cnn/%E5%9B%BE6.jpg" class="img-fluid rounded" width="100%" height="auto" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <p>这幅图是 Ke Tan，DeLiang Wang 的论文 “A Convolutional Recurrent Neural Network for Real-time speech enhancement” 中的图，笔者就是根据这幅图理解的因果卷积。从下往上看，这幅图可以理解为 Encoder 的计算过程，从上往下看，这幅图可以理解为 Decoder 的计算过程。只要能完全理解这幅图片，什么 Encoder 架构，Encoder-Decoder 架构，什么输入层补零，逐层补零都不是问题，可以做到 “一图走天下”。</p> <p>在 CNN 的基础上能构建的网络形式有很多，比如设置 stride&gt;1，dilation&gt;1，比如网络中加入残差链接等。在 coding 的过程中，需要认真分析搭建的网络结构，以正确地控制网络的因果性和感受野。</p>]]></content><author><name></name></author><category term="神经网络"/><category term="神经网络"/><category term="CNN"/><summary type="html"><![CDATA[本文对笔者关于 CNN 因果性的理解作以记录。如有表述不当之处欢迎批评指正。欢迎任何形式的转载，但请务必注明出处]]></summary></entry><entry><title type="html">基频提取算法-PYIN</title><link href="https://xinleiren.github.io/blog/2024/pyin/" rel="alternate" type="text/html" title="基频提取算法-PYIN"/><published>2024-12-17T00:00:00+00:00</published><updated>2024-12-17T00:00:00+00:00</updated><id>https://xinleiren.github.io/blog/2024/pyin</id><content type="html" xml:base="https://xinleiren.github.io/blog/2024/pyin/"><![CDATA[<p>请阅读 <a href="/assets/html/pyin.html">基频提取算法-PYIN</a></p>]]></content><author><name></name></author><category term="基频提取"/><category term="pitch"/><category term="pyin"/><summary type="html"><![CDATA[本文对基频提取算法 PYIN 做以介绍。如有表述不当之处欢迎批评指正。欢迎任何形式的转载，但请务必注明出处。]]></summary></entry><entry><title type="html">基频提取算法-YIN</title><link href="https://xinleiren.github.io/blog/2024/yin/" rel="alternate" type="text/html" title="基频提取算法-YIN"/><published>2024-12-16T00:00:00+00:00</published><updated>2024-12-16T00:00:00+00:00</updated><id>https://xinleiren.github.io/blog/2024/yin</id><content type="html" xml:base="https://xinleiren.github.io/blog/2024/yin/"><![CDATA[<p>请阅读 <a href="/assets/html/yin.html">基频提取算法-YIN</a></p>]]></content><author><name></name></author><category term="基频提取"/><category term="pitch"/><category term="yin"/><summary type="html"><![CDATA[本文对基频提取算法 YIN 做以介绍。如有表述不当之处欢迎批评指正。欢迎任何形式的转载，但请务必注明出处。]]></summary></entry><entry><title type="html">【论文笔记之 PYIN】PYIN, A Fundamental Frequency Estimator Using Probabilistic Threshold Distributions</title><link href="https://xinleiren.github.io/blog/2024/paper-pyin/" rel="alternate" type="text/html" title="【论文笔记之 PYIN】PYIN, A Fundamental Frequency Estimator Using Probabilistic Threshold Distributions"/><published>2024-12-15T00:00:00+00:00</published><updated>2024-12-15T00:00:00+00:00</updated><id>https://xinleiren.github.io/blog/2024/paper-pyin</id><content type="html" xml:base="https://xinleiren.github.io/blog/2024/paper-pyin/"><![CDATA[<p>请阅读 <a href="/assets/html/paper-pyin.html">【论文笔记之 PYIN】PYIN, A Fundamental Frequency Estimator Using Probabilistic Threshold Distributions</a></p>]]></content><author><name></name></author><category term="论文笔记"/><category term="pitch"/><category term="pyin"/><summary type="html"><![CDATA[本文对 Matthias Mauch 和 Simon Dixon 等人于 2014 年在 ICASSP 上发表的论文进行简单地翻译。如有表述不当之处欢迎批评指正。欢迎任何形式的转载，但请务必注明出处。]]></summary></entry><entry><title type="html">【论文笔记之 YIN】YIN, a fundamental frequency estimator for speech and music</title><link href="https://xinleiren.github.io/blog/2024/paper-yin/" rel="alternate" type="text/html" title="【论文笔记之 YIN】YIN, a fundamental frequency estimator for speech and music"/><published>2024-12-14T00:00:00+00:00</published><updated>2024-12-14T00:00:00+00:00</updated><id>https://xinleiren.github.io/blog/2024/paper-yin</id><content type="html" xml:base="https://xinleiren.github.io/blog/2024/paper-yin/"><![CDATA[<h2 id="1-论文目的">1. 论文目的</h2> <p>提出一种语音和音乐场景下估计基频的方法：YIN.</p> <h2 id="2-摘要">2. 摘要</h2> <p>论文提出了一种用于估计语音和音乐基频（$F_0$）的算法。该算法基于著名的自相关方法，并加入了一些修改，以减少错误。在语音和喉镜信号数据集上的评估显示，该算法的错误率比最佳竞争方法低 3 倍左右。由于没有对频率搜索范围的上界做限制，因此，该算法适合音调较高的声音和音乐。算法相对简单，延迟低，而且可调参数少。该算法基于一个周期信号模型，该模型可以以各种方式被扩展，以处理特定应用中出现的各种形式的非周期性。</p> <h2 id="3-介绍">3. 介绍</h2> <p>周期信号的基频（$F_0$）是其周期的逆，而周期可以定义为：使得信号保持不变的所有时间偏移集合中的最小正整数。该定义只适用于完美的周期性信号。然而，所关注的语音或音乐信号并不具备完美的周期性，基频估计的艺术就是以有用且一致的方式来处理这类信号。</p> <p>声音的主观音高 （pitch） 通常取决于它的基频，但也有例外。然而，宽泛地来说，音高和周期是一对一的关系。以至于“音高”一词通常被用来代替 $F_0$，而且 $F_0$ 估计方法通常被称为 “音高检测算法” 或 PDA（pitch detection algorithms）. 现代音高感知模型假设：音高要么来源于时域中神经模式的周期性，要么来源于耳蜗在频域中分辨出的局部谐波模式。这两个过程都会产生基频或者周期。</p> <p>一些应用给出了对 $F_0$ 的不同定义。对于语音来说，$F_0$ 通常定义为声带的振动频率。声门处的周期性振动可能产生不太完美的周期性语音，because of movements of the vocal tract that filters the glottal source waveform. 然而，声门振动本身也会表现出非周期性。各种因素叠加在一起，使得获得语音信号 $F_0$ 的有用估计是相当困难的。尽管已经有很多方法被提了出来，但 $F_0$ 估计是一个持续吸引业界关注的话题。最全面的综述出自于 Hess, 由 Hess 或 Hermes 作以更新。近期的方法包括：瞬时频率法、统计学习和神经网络、听觉模型等，当然还有很多其它的方法。</p> <p>$F_0$ 可被用于很多应用中，在语音识别系统中使用 $F_0$ 的尝试已经取得了一定的成功。一些音乐类的应用需要估计 $F_0$, 比如自动乐谱转录或实时交互系统。$F_0$ 是许多信号处理方法中很有用的特征。</p> <p>本文介绍了一种比其它著名方法产生更少错误的 $F_0$ 估计方法。名称 “YIN” （来自于东方哲学的“阴”和“阳”）暗示了它所涉及的 autocorrelation 和 cancellation 之间的相互作用。</p> <h2 id="4-方法">4. 方法</h2> <p>本章逐步介绍该方法，以深入了解该方法的有效性。首先，给出了经典的自相关算法；接着，分析了其误差机理；最后，提出了一系列的改进措施来降低错误率；出于说明目的，每一步都在一个小数据集上对错误率进行了测试。下一章提出了更全面的评估。</p> <h3 id="a-步骤-1-自相关方法">A. 步骤 1 自相关方法</h3> <p>离散信号 $x_t$ 的自相关函数 (ACF) 可以被定义为： \(\begin{align} r_t(\tau) = \sum_{j=t+1}^{t+W} x_j x_{j+\tau}, \end{align}\)</p> <p>其中，$r_t(\tau)$ 是在 $t$ 时刻计算的滞后了 $\tau$ 之后的自相关函数，$W$ 是积分窗口的长度。图 1 给出了一个示例。在信号处理中，通常使用略微不同的定义： \(\begin{align} r_t^{'}(\tau) = \sum_{j=t+1}^{t+W-\tau} x_j x_{j+\tau}. \end{align}\)</p> <p>这里积分窗口的长度随着 $\tau$ 值的增加而减少，这会导致函数的包络线作为滞后的函数而减少。如果信号在区域 $\left[t+1, t+W\right]$ 之外的值全是零，那么上述两个定义将给出相同的结果，否则，将给出不同的结果。除非另有说明，否则本文采用第一种定义。</p> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/paper_yin/%E5%9B%BE1-480.webp 480w,/assets/img/paper_yin/%E5%9B%BE1-800.webp 800w,/assets/img/paper_yin/%E5%9B%BE1-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/assets/img/paper_yin/%E5%9B%BE1.png" class="img-fluid rounded" width="100%" height="auto" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <p>对于周期信号，ACF 在周期的倍数处显示出了峰值。“自相关方法”通过在滞后范围内的穷举搜索来选择最高的非零滞后峰值（图 1 中水平箭头）。显然，如果下限太接近零，算法可能会错误地选择零滞后峰值。反过来，如果上限足够大，它可能会错误地选择更高阶的峰值。$(1)$ 中的定义很容易出现第二个问题，而 $(2)$ 中的定义又很容易出现第一个问题（当窗口长度 $W$ 较小时，更是如此）。</p> <p>为了评估 tapered ACF 包络对错误率的影响，对 $(1)$ 中计算的函数乘以 a negative ramp 来模拟 $(2)$ 的结果，且令 $W=\tau_{max}$: \(\begin{align} r_t^{''}(\tau) = \left\{ \begin{array}{lc} r_t(\tau)(1-\tau/\tau_{max}) &amp; \text{if} \; \tau \leq \tau_{max}, \\ 0, &amp; \text{otherwise}. \\ \end{array} \right. \end{align}\)</p> <p>在一个小语音数据集上对错误率进行了评估（细节参见下章），并在图 2 中给出了其与 $\tau_{max}$ 的关系。参数 $\tau_{max}$ 允许算法以牺牲两种错误中的一种为代价，而偏向另一种，with a minimum of total error for intermediate values. 如果使用 $(2)$ 而不是 $(1)$ 会引入 a natural bias that can be tuned by adjusting $W$. 然而，改变窗长还会产生其它影响，and one can argue that a bias of this sort, if useful, should be applied explicitly rather than implicitly. 这是为啥使用 $(1)$ 的原因之一。</p> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/paper_yin/%E5%9B%BE2-480.webp 480w,/assets/img/paper_yin/%E5%9B%BE2-800.webp 800w,/assets/img/paper_yin/%E5%9B%BE2-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/assets/img/paper_yin/%E5%9B%BE2.png" class="img-fluid rounded" width="100%" height="auto" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <p>自相关方法将信号与其自身的平移版本进行比较。从这个意义上讲它和 AMDF（average magnitude difference function）方法是有关联的，后者比较的是差值而不是乘积，而且它是一种更通用的测量事件之间时间间隔的时域方法。ACF 是功率谱的傅立叶变换，and can be seen as measuring the regular spacing of harmonics within that spectrum. 倒谱方法用对数幅度谱代替功率谱，因此对频谱的高频幅度部分所施加的权重变小（particularly near the first formant that often dominates the ACF.） 类似地，‘谱白化’（’spectral whitening’）效果可以通过线性预测逆滤波（linear predictive inverse filtering）或者中心剪切（center-clipping），或者通过使用滤波器组对信号进行分解，然后在每个通道内计算 ACFs，并将幅度归一化之后的结果相加来得到。基于自相关的听觉模型是目前解释音高感知的更流行的方法之一。</p> <p>尽管自相关方法（以及与此相关的其它方法）很具有吸引力，而且研究者们付出了很多努力来提升其性能，但它在许多应用中仍会产生很多错误。接下来的内容会逐步降低其错误率。表 1 的第一行给出了基于 $(1)$ 的基础自相关方法所产生的 gross error rate（定义在下一章中，且是在下一章所使用的数据集的一个子集上测量的）。表 1 中的其它行是通过一系列改进所得到的结果，下一章给出了更正式的报告。</p> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/paper_yin/%E8%A1%A81-480.webp 480w,/assets/img/paper_yin/%E8%A1%A81-800.webp 800w,/assets/img/paper_yin/%E8%A1%A81-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/assets/img/paper_yin/%E8%A1%A81.png" class="img-fluid rounded" width="100%" height="auto" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <h3 id="b-步骤-2-差分函数">B. 步骤 2 差分函数</h3> <p>首先，将信号 $x_t$ 建模为周期为 $T$ 的周期函数，可得： \(\begin{align} x_t - x_{t+T} = 0, \quad \forall t. \end{align}\)</p> <p>在一个窗口内对其取平方、求均值后也是如此： \(\begin{align} \sum_{j=t+1}^{t+W} (x_j - x_{j+T})^2 = 0. \end{align}\)</p> <p>反过来，可以通过计算差分函数，并搜找使得函数值为零的 $\tau$ 值，来找到一个未知的周期： \(\begin{align} d_t(\tau) = \sum_{j=1}^{W}(x_j-x_{j+\tau})^2, \end{align}\)</p> <p>存在无数这样的值，它们都是周期的整数倍。图 3(a) 给出了在图 1(a) 的信号上计算出的差分函数。将平方和展开之后，可以使用 ACF 来描述差分函数： \(\begin{align} d_t(\tau) = r_t(0) + r_{t+\tau}(0) - 2r_t(\tau). \end{align}\)</p> <p>前两项是能量项，如果它们是常数，那么差分函数 $d_t(\tau)$ 将与 $r_t(\tau)$ 呈负相关，进一步，寻找其中一个函数的最小值或寻找另一个函数的最大值将会得到相同的结果。然而，第二项能量项会随着 $\tau$ 值的变化而变化，这意味着 $r_t(\tau)$ 的最大值和 $d_t(\tau)$ 的最小值不一定一一对应。实际上，错误率从无偏自相关的 10.0% 降低到了差分函数的 1.95%（见表 1）。</p> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/paper_yin/%E5%9B%BE3-480.webp 480w,/assets/img/paper_yin/%E5%9B%BE3-800.webp 800w,/assets/img/paper_yin/%E5%9B%BE3-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/assets/img/paper_yin/%E5%9B%BE3.png" class="img-fluid rounded" width="100%" height="auto" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <p>错误率的降幅是令人惊讶的。一个解释是根据 $(1)$ 实现的 ACF 对幅度的变化相当敏感。正如 Hess 在他之前的文献中所指出的那样，如果信号幅度随着时间增加，那么 ACF 的峰值幅度会随着滞后 $\tau$ 的增加而增加，而不会是像图 1(b) 那样保持恒定。这会使得算法趋向于选择一个更高阶的峰值，并产生一个 “too low” 的错误（幅度降低会产生相反的效果）。而差分函数不受这个特定问题的影响，as amplitude changes cause period-to-period dissimilarity to increase with lag in all cases. Hess 指出 $(2)$ 对幅度变化不太敏感[$\text{(A1)}$ 也具有该属性]。然而，使用 $d(\tau)$ 具有额外的吸引力，它更紧密地基于 $(4)$ 中的信号模型，而且为接下来的两个减少错误的步骤铺平了道路，第一个是 “too high” 错误，第二个是 “too low” 错误。</p> <h3 id="c-步骤-3-累积均值归一化差分函数">C. 步骤 3 累积均值归一化差分函数</h3> <p>在零滞后的时候，图 3(a) 所示的差分函数值为零，并且由于不完美的周期性，在周期处，其值通常不为零。除非对搜索范围设置下限，否则算法一定会选择零滞后的值，而不是周期处的值，这会导致该方法必定失败。即使设置了下限，第一共振峰（$F_1$）处的强烈共振可能会产生一系列的二次凹陷，其中的某个可能会比周期凹陷更深。搜索范围的下限设置并不是避免该问题的满意方法，因为已知的 $F_0$ 和 $F_1$ 的范围是重叠的。</p> <p>作者提出的解决方案是使用累积均值归一化差分函数（ “cumulative mean normalized difference function”）代替差分函数: \(\begin{align} d_t^{'}(\tau) = \left\{ \begin{array}{lc} 1, &amp; \text{if} \; \tau = 0, \\ d_t(\tau)/[(1/\tau)\sum_{j=1}^{\tau}{d_t(j)}], &amp; \text{otherwise}. \\ \end{array} \right. \end{align}\)</p> <p>它与 $d(\tau)$ 的不同之处在于它的值从 $1$ 而不是从 $0$ 开始，在低滞后时，其值也往往比较大，而且仅当 $d(\tau)$ 低于平均值时，其值才会小于 $1$（见图 3(b) ）。使用 $d^{‘}$ 代替 $d$ 降低了 “too high” 错误，错误率从 1.95% 降到了 1.69%。第二个好处是取消了搜索范围的频率上限，不再需要 avoid the zero-lag dip. 第三个好处是对函数进行了归一化，更方便后续的进一步优化。</p> <h3 id="d-步骤-4-绝对阈值">D. 步骤 4 绝对阈值</h3> <p>很容易出现的一种情况是，差分函数（图 3(b) ）的高阶凹陷中的某个会比周期凹陷更深。如果前者正好处于搜索范围之内，将会导致次谐波错误，有时候称之为 “octave error”（该说法不严谨，因为与真正基频的比率不一定是 $2$ 的整数次幂）。自相关方法同样也比较容易选择高阶峰值。</p> <p>作者提出的解决方案是预设一个绝对阈值，and choose the smallest value of $\tau$ that gives a minimum of $d^{‘}$ deeper than that threshold. If none is found, the global minimum is chosen instead. 当阈值为 $0.1$ 时，错误率从 1.69% 降到了 0.78%，这是 “too low” 错误降低，”too high” 错误略微增加而产生的结果。</p> <p>该步骤实现了短语 “the period is the smallest positive member of a set” 中的单词 “smallest”（前述步骤实现了单词 “positive”）。预设阈值决定了进入该集合的候选列表，并且可以将其解释为 the proportion of aperiodic power tolerated within a “periodic” signal. 要看到这一点，考虑以下等式: \(\begin{align} 2(x_t^2 + x_{t+T}^2) = (x_t + x_{t+T})^2 + (x_t - x_{t+T})^2. \end{align}\)</p> <p>在一个窗口内对上式取均值，并且除以 $4$ 可得： \(\begin{align} 1/(2W) \sum_{j=t+1}^{t+W}(x_j^2 + x_{j+T}^2) \notag \\ = 1/(4W) \sum_{j=t+1}^{t+W}(x_j + x_{j+T})^2 + \notag \\ 1/(4W) \times \sum_{j=t+1}^{t+W}(x_j - x_{j+T})^2. \end{align}\)</p> <p>等式左边近似于信号的功率，等式右边的两项将总功率进行了划分。如果是周期为 $T$ 的周期信号，那么右边第二项将为零，and is unaffected by adding or subtracting periodic components at that period. 它可以被解释为信号功率的“非周期功率”成分。当 $\tau=T$ 时，$(8)$ 中的分子与非周期功率成正比，而其分母（对 $d(\tau)$ 在 $\tau=[0,T]$ 范围内进行了平均）大约是信号功率的两倍。因此，$d^{‘}(T)$ 与非周期功率/总功率的比值成正比。如果该比值低于阈值，那么候选值 $T$ 也是满足上述集合要求的。后续将看到，该阈值的精确值不会严重影响错误率。</p> <h3 id="e-步骤-5-抛物线插值">E. 步骤 5 抛物线插值</h3> <p>如果信号周期是采样周期的整数倍，那么按照上述所说的步骤来执行是没什么问题的。而如果不是，那么估计出来的值将会有问题。</p> <p>该问题的解决方案之一是使用抛物线插值。对每个 $d^{‘}(\tau)$ 局部极小值及其相邻的值进行抛物线拟合，and the ordinate of the interpolated minimum is used in the dip-selection process. The abscissa of the selected minimum then serves as a period estimate. 事实上，人们发现用这种方式得到的估计是有偏的。为了避免该偏差，使用原生差分函数 $d(\tau)$ 相应的极小值的横坐标来代替。</p> <p>对 $d^{‘}(\tau)$ 或 $d(\tau)$ 进行插值比对信号进行上采样的计算复杂度更低，and accurate to the extent that $d^{‘}(\tau)$ can be modeled as a quadratic function near the dip. Simple reasoning argues that this should be the case if the signal is band-limited. 首先，回顾下 ACF 是功率谱的傅立叶变换：如果 $x_t$ 是带限信号，那么它的 ACF 也是如此。然后，ACF 是余弦之和，which can be approximated near zero by a Taylor series with even powers. $4$ 次或更高次数的项主要来自于最高频率成分，如果这些分量不存在或较弱，那么函数可以由较低阶的项来准确地表示（二次项和常量）。最后，要注意的是周期峰值和零滞后峰值具有相同的形状，and the same shape（modulo a change in sign）as the period dip of $d(\tau)$, which in turn is similar to that of $d^{‘}(t)$. 因此，除非信号包含强高频分量（实际中，高于采样率的四分之一），否则 parabolic interpolation of a dip is accurate. 插值对数据集中的 gross error rate 几乎没有影响（$0.77%$ vs $0.78%$）, 可能是因为 $F_0$’s were small in comparison to the sampling rate. 然而，在合成数据上的测试发现，抛物线插值可以减少所有 $F_0$ 的 fine error，而且避免高 $F_0$ 处的 gross errors.</p> <h3 id="f-步骤-6-最优局部估计">F. 步骤 6 最优局部估计</h3> <p>式 $(1)$ 和 $(6)$ 中积分的作用是为了确保估计是稳定的，并且不会在基本周期的时间尺度上波动。相反，如果观察到任何此类波动，则不应被视为真实的波动。有时候会发现，对于非平稳语音间隙，that the estimate fails at a certain phase of the period that usually coincides with a relatively high value of $d^{‘}(T_t)$, 其中 $T_{t}$ 是时刻 $t$ 估计出来的周期。而在另一个阶段（时刻 $t^{‘}$）, 估计出来的值可能是正确的，而且 $d^{‘}(T_{t^{‘}})$ 的取值更小。步骤 $6$ 利用这一事实，通过在每个分析点附近 “shopping”, 以获得更好的估计。</p> <p>算法如下所述。对每个时刻 $t$, 在一个小的时间间隔 $[t-T_{max}/2, t+T_{max}/2]$ 内寻找使得 $d_{\theta}^{‘}(T_{\theta})$ 取最小值的 $\theta$, 其中 $T_{\theta}$ 是在时刻 $\theta$ 估计的周期，而 $T_{max}$ 是期望的最大周期。基于该初始估计，在有限的搜索范围内再次使用估计算法来得到最终的估计。使用 $T_{max}=\text{25ms}$，以及初始估计的 $\pm \text{20\%}$ 的最终搜索范围，步骤 6 将错误率从 $0.77\%$降为 $0.5\%$。步骤 6 使人想起中值平滑或动态规划技术，但不同之处在于它考虑了相对较短的时间间隔，并根据质量而不仅仅是连续性进行选择。</p> <p>步骤 1~6 的组合构成了一个新的方法（YIN）, 后续章节将其与其它方法进行比较以进行评估。值得注意的是这些步骤之间是如何相互构建的。使用差分函数（步骤 2）来代替 ACF（步骤 1）为累积均值归一化操作（步骤 3）铺平道路，阈值方案（步骤 4）和用于选择最优局部估计的测量值 $d^{‘}(T)$ 以此为基础。抛物线插值（步骤 5）独立于其它步骤，尽管它依赖于 ACF（步骤 1） 的谱特性。</p> <h2 id="5-评估">5. 评估</h2> <p>到目前为止的错误率只是说明性的。本章节将新方法与以前的方法进行对比，以做一个更正式的评估。附录给出了测试集的详细情况。喉镜数据的 $F0$ 是自动估计出来的，而且人为剔除了那些看似不正确的值。该过程也去除了清音和不规则的浊音部分（diplophony, creak）。 在评估候选方法的时候，与喉镜数据的估计值相差超过 20% 的值被视为 “gross error”. 许多研究都使用了这种相对宽松的标准，并在以下假设下衡量任务的困难部分：如果初始估计的正确率在 20% 以内，则可以使用多种技术中的任意一种来改进它。Gross errors 进一步细分为 “too low” 错误（主要是次谐波）和 “too high” 错误。</p> <p>错误率本身并不能提供信息，因为它取决于数据库的难度。为了得出有用的结论，必须在相同的数据集上对不同的方法做评估。幸运的是，可免费访问的数据库和软件使这件事变得容易。附录中给出了本文所对比的方法及一些参数的详细信息。简单来说，禁用后处理和 voiced–unvoiced 决策机制（如果可能的话），而且搜索的范围都是 40~800hz，但 YIN 除外，其上限为采样率的四分之一。</p> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/paper_yin/%E8%A1%A82-480.webp 480w,/assets/img/paper_yin/%E8%A1%A82-800.webp 800w,/assets/img/paper_yin/%E8%A1%A82-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/assets/img/paper_yin/%E8%A1%A82.png" class="img-fluid rounded" width="100%" height="auto" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <p>表 2 总结了每个方法在不同数据集上的错误率。这些数字不应被视为每种算法或实现的内在质量的一个准确衡量，因为评估条件与其优化条件不同。特别是搜索范围特别宽（40~800hz），可能会导致那些为较窄搜索范围设计的方法出现不稳定，几种方法的 “too low” 和 “too high” 错误率之间的不平衡就证明了这一点。相反，这些数字是对已知算法在这些困难条件下的“现成”实现的预期性能的抽样。值得注意的是，在不同的数据集上算法的排名有差异。比如 “acf” 和 “nacf” 算法在 DB1（一个包含 28 个说话人的大数据集 ）上表现得很出色，但在别的数据集上表现得一般。这说明需要在广泛的数据集上进行测试。</p> <p>在所有的数据集上，YIN 表现得最好。在所有数据集上平均之后，YIN 的错误率比其它算法中表现最好的小 3 倍左右。错误率取决于用于决定估计正确与否的容忍度。对于 YIN，大约 99% 的估计准确度在 20% 以内，94% 的估计准确度在 5% 以内，60% 的估计准确度在 1% 以内。</p> <h2 id="6-对参数的敏感度">6. 对参数的敏感度</h2> <p>对于大多数方法而言，$F_0$ 的搜索上界和下界是一个很重要的参数。与其它方法相比，YIN 不需要上界限制（然而，对于 $F_0$ 超过采样率四分之一的情况，它往往会失败）。这使得它在音乐相关的应用中是十分有用的，在这些应用中, $F_0$ 会很高。较大的搜索范围往往会增加找到错误估计的可能性。因此尽管搜索范围较宽，但错误率相对较低，这表明了 YIN 算法的鲁棒性。</p> <p>在一些方法中[基于谱的和基于公式 $(2)$ 的自相关方法]，窗长即决定了可以估计的最大周期（$F_0$ 搜索范围的下限），也决定了用来积分以获得任意特定估计的数据量。对于 YIN 来说，这两个量是解耦的（$T_{max}$ 和 $W$）。然而，这两个量之间存在某种关系。为了使估计值随时间保持稳定，积分窗口必须不短于最大的期望周期。否则，one can construct stimuli for which the estimate would be incorrect over a certain phase of the period. 最大期望周期显然也决定了需要计算的滞后范围，这些考量一起证明了以下众所周知的经验法则：$F_0$ 估计需要足够的信号来覆盖两倍的最大期望周期。然而，窗长可能会很大，而且经常可以观察到：窗长越大，错误越少，但代价是估计的时间序列的时间分辨率降低。YIN 的统计报告是在积分窗口 25ms 和周期搜索范围 25ms 的情况下获得的，这是 $F_0$ 的下限 40hz 能兼容的最短时间。图 4(a) 给出了不同窗长下的错误数量。</p> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/paper_yin/%E5%9B%BE4-480.webp 480w,/assets/img/paper_yin/%E5%9B%BE4-800.webp 800w,/assets/img/paper_yin/%E5%9B%BE4-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/assets/img/paper_yin/%E5%9B%BE4.png" class="img-fluid rounded" width="100%" height="auto" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <p>YIN 特有的一个参数是步骤 4 中用到的阈值。图 4(b) 展示了它是如何影响错误率的。显然它不需要微调，至少对于这个任务来说是这样。此处使用的值是 $0.1$。最后一个参数是信号初始低通滤波的截止频率。通常观察到，低通滤波会使这些方法减少错误，但显然将截止频率设置在 $F_0$ 以下会导致估计失败。这里使用 1-ms 的方窗进行卷积（零点在 1kHz 处）。图 4(c) 给出了其它数值的错误率。总的来说，YIN 涉及到的参数较少，并且这些参数不需要微调。</p> <h2 id="7-实现考虑">7. 实现考虑</h2> <p>YIN 的基本组成部分是定义在 $(1)$ 里面的函数。直接按照公式进行计算的话，其计算复杂度是非常高的，不过有两个方法可以降低其复杂度。第一种是在时间维度上使用递归的方式实现 $(1)$（每一步增加一个新的项，并减去一个旧的项目），窗是方窗，但可以通过递归获得三角窗或近似于高斯窗（但是没有什么理由不使用方窗）。</p> <p>第二种方法是使用 $(2)$，它可以使用 FFT 来高效地计算。不过这会引出两个问题。第一个问题是 $(7)$ 中的能量项必须分开计算。它们与 $r^{‘}_t(0)$ 不同，而分别是窗口内第一个和最后一个 $W-\tau$ 个采样点的平方和。必须在每个 $\tau$ 值上都对它们进行计算，不过这可以通过在 $\tau$ 上递归来高效实现。第二个问题是小的 $\tau$ 值所涉及求和项比大的 $\tau$ 要多。这会引入不必要的偏差，不过该偏差可以通过对 $d(\tau)$ 的每个样本除以 $W-\tau$ 来进行纠正。然而，当 $\tau$ 取值较大时，$d(\tau)$ 是从较短窗口的数据中计算得到的，因此不如 $\tau$ 取较小值时稳定。在这个意义上，FFT 实现并不如第一种方法好。然而，在较低的帧率上进行估计时，第二种方法更快。如果需要高分辨率时间序列的估计，则第一种方法可能更快。</p> <p>交互式音乐跟踪等实时应用需要低延迟。前面提到过，估计至少需要的信号样本量为 $2T_{max}$。然而，步骤 4 允许计算从 $\tau=0$ 开始，直到找到可接受的候选结果为止，而不是在整个搜索范围上进行处理，所以延迟可以被降低到 $T_{max} + T$。仅当积分时间降低到 $T_{max}$ 以下时，才有可能进一步减少延迟，which opens the risk of erroneously locking to the fine structure of a particularly long period.</p> <p>$d^{‘}(T)$ 可以作为置信度指标（大的值表示 $F0$ 估计可能不太可靠），in postprocessing algorithms to correct the $F0$ trajectory on the basis of the most reliable estimates, and in template-matching applications to prevent the distance between a pattern and a template from being corrupted by unreliable estimates within either. 另一个应用是在多媒体索引中，$F_0$ 的时间序列不得不被下采样以节省空间。置信度度量允许基于正确而不是错误的估计来进行下采样。该方案在 MPEG7 standard (ISO/IEC–JTC–1/SC–29, 2001) 中实现。</p> <h2 id="8-扩展">8. 扩展</h2> <p>第 4 章描述的 YIN 算法基于 $(4)$ 的模型（周期信号）。模型的概念很有洞察力：“估计错误”仅仅意味着 that the model matched the signal for an unexpected set of parameters. 错误降低涉及修改模型以降低此类匹配的可能性。本章给出了扩展的模型，以解决信号系统性地偏离周期模型的情况。通过在语音数据库上的定量测试，这些扩展的模型均没有提高错误率，可能是因为 YIN 所使用的周期模型对这项任务来说足够准确。基于此，论文没有给出正式的评估结果。本章的目的是展示该方法的灵活性并为未来的发展开辟前景。</p> <h3 id="a-变化的幅度">A. 变化的幅度</h3> <p>语音和音乐中经常出现的幅度变化会损害周期模型的拟合度，从而产生误差。为了处理这种情况，信号可以被建模成时变幅度的周期函数： \(\begin{align} x_{t+T}/a_{t+T} = x_{t}/a_{t}. \end{align}\)</p> <p>如果假设 $\alpha = a_{t+T}/a_{t}$ 不依赖于 $t$ (如指数增加或减少), $\alpha$ 的值可以通过最小二乘拟合出来。将该值代入 $(6)$ 中，可以得到：</p> \[\begin{align} d_{t}(\tau) = r_{t}(0)[1-r_{t}(\tau)^{2}/r_{t}(0)r_{t+\tau}(0)]. \end{align}\] <p>图 5 说明了该结果。最上面的图展示了时变信号，中间的图展示了根据标准处理流程推导出的 $d^{‘}(\tau)$，最下面的图展示了使用 $(12)$ 而不是 $(6)$ 推导出的相同的函数。有趣的是，$(12)$ 右边的第二项是归一化 ACF 的平方。</p> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/paper_yin/%E5%9B%BE5-480.webp 480w,/assets/img/paper_yin/%E5%9B%BE5-800.webp 800w,/assets/img/paper_yin/%E5%9B%BE5-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/assets/img/paper_yin/%E5%9B%BE5.png" class="img-fluid rounded" width="100%" height="auto" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <p>具有两个参数的模型 $(12)$ 更加“宽容”，更容易拟合幅度变化的信号。然而，这也意味着会出现更多“不期望”的拟合，也就是出现更多错误。或许正是因为这个原因，其错误率确实有所增加（在受限数据库上 0.57% vs. 0.50%）。然而，它被成功地用于处理喉镜信号（见附录）。</p> <h3 id="b-变化的基频">B. 变化的基频</h3> <p>幅度变化在语音和音乐中也很常见，是干扰 $F_{0}$ 估计的第二个非周期性来源。当 $F_{0}$ 为常量时，也许可以找到一个滞后 $\tau$，使得 $(x_{j} - x_{j+\tau})^2$ 在 $d(\tau)$ 的整个积分窗口上都是 $0$，但是对于一个时变的 $F_{0}$，它只在某一点上等于 $0$。在任意一侧，$(x_{j}-x_{j+\tau})^{2}$ 的值随着距离该点的距离成二次方变化，因此，$d(\tau)$ 随着窗长 $W$ 成立方变化。</p> <p>较短的窗可以改善匹配性能，但我们知道积分窗口不得短于特定限制（见第 6 章）。一个解决办法是将窗口划分为两个或更多的片段，并允许片段之间的 $\tau$ 在已有限制内取不同值，该已有限制取决于最大的期望变化率。Xu 和 Sun (2000) 给出 $F_{0}$ 的最大变化率大约是 $\pm6 \, \text{oct/s}$, 但是在我们的数据库中，它通常不会超出 $\pm1 \, \text{oct/s}$ (图 10)。使用划分后的窗口，搜索空间更大，但匹配得到改善（在两个片段的情况下，by a factor of up to $8$）。同样，该模型比 $(4)$ 更容易满足，因此可能会引入新的错误。</p> <h3 id="c-dc-缓慢变化的加性噪声">C. DC 缓慢变化的加性噪声</h3> <p>非周期性的一个常见来源是加性噪声，它有很多种形式。第一种形式是随时间变化的 DC，例如当麦克风太近，歌手呼吸时就会产生。图 6(b) 展示了 a DC ramp 的不利影响，不过可以使用以下公式消除该影响（如图 6(c) 所示），该公式是通过将 $d_t(\tau)$ 对 DC 偏移的导数设置为 $0$ 来得到的： \(\begin{align} d_{t}(\tau) = r_{t}(0) + r_{t+\tau}(0) - 2r_{t}(\tau) + [\sum_{j=t+1}^{t+W}(x_{j} - x_{j+\tau})]^{2} \end{align}\)</p> <p>同样，该模型比严格的周期性模型更宽松，因此也可能会引入新的错误。基于此并且因为语音数据不包含明显的 DC 偏移，所以它并没有带来任何改进，反而略微增加了错误率（$0.51\%$ vs $0.5\%$）。然而，它可以用于处理喉镜信号，这些信号具有较大的缓慢变化的偏移。</p> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/paper_yin/%E5%9B%BE6-480.webp 480w,/assets/img/paper_yin/%E5%9B%BE6-800.webp 800w,/assets/img/paper_yin/%E5%9B%BE6-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/assets/img/paper_yin/%E5%9B%BE6.png" class="img-fluid rounded" width="100%" height="auto" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <h3 id="d-周期性的加性噪声">D. 周期性的加性噪声</h3> <p>加性噪声的第二种形式是并发的周期性声音，例如人声、乐器或嗡嗡声等。除了周期处于某些简单比率的不幸情况外，可以使用冲激响应为 $h(t) = \delta(t) - \delta(t+U)$ 的梳状滤波器来消除干扰声的影响，其中 $U$ 是干扰信号的周期。如果 $U$ 已知，那么该处理过程就很简单。而如果 $U$ 未知，那么它和周期 $T$ 都可以通过联合估计算法找到。该联合估计算法搜索 $(\tau, v)$ 参数空间以使下式取得最小值： \(\begin{align} dd_{t}(\tau, v) = \sum_{j=t+1}^{t+W}(x_{j} - x_{j+\tau} - x_{j+v} + x_{j+\tau+v})^{2}. \end{align}\)</p> <p>上述计算的复杂度较高，然而可以通过使用下式来大幅降低复杂度： \(\begin{align} dd_{t}(\tau, v) &amp;= r_{t}(0) + r_{t+\tau}(0) + r_{t+v}(0) + r_{t+\tau+v}(0) \notag \\ &amp;- 2r_{t}(\tau) - 2r_{t}(v) + 2r_{t}(\tau+v) \notag \\ &amp;+2r_{t+\tau}(v - \tau) - 2r_{t+\tau}(v) - 2r_{t+v}(\tau). \end{align}\)</p> <p>等式右边与用于单周期估计的 ACF 系数相同。如果它们已事先计算好，那么 $(15)$ 的计算复杂度就相当低。两周期模型同样更加宽松，因此也可能会引入新的错误。</p> <h3 id="e-与目标频谱不同的加性噪声">E. 与目标频谱不同的加性噪声</h3> <p>现在假设加性噪声既不是 DC 也不是周期性的，但是它的谱包络不同于周期性目标信号的谱包络。如果这两个长时谱都是已知且稳定的，那么可以使用滤波的方法来增强目标信号，并且减弱干扰信号。低通滤波器是一种简单的方法，其影响如图 4(c) 所示。</p> <p>如果目标信号和噪声的频谱仅在短期内有所不同，那么有两种技术可选。第一种技术首先使用滤波器（比如，听觉模型滤波器组）组对信号进行分带，然后计算每个输出的差分函数，最后将这些函数相加获得一个汇总的差分函数，可以从该汇总的差分函数中推导出周期性度量。然后将各个通道（笔者理解应该是划分后的子带）一一删除，直到周期性得到改善。</p> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/paper_yin/%E5%9B%BE7-480.webp 480w,/assets/img/paper_yin/%E5%9B%BE7-800.webp 800w,/assets/img/paper_yin/%E5%9B%BE7-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/assets/img/paper_yin/%E5%9B%BE7.png" class="img-fluid rounded" width="100%" height="auto" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <p>第二种技术对输入信号应用一个自适应滤波器，并且联合搜索周期和滤波器的参数。这对于冲激响应为 $h(t) = \delta(t) \pm \delta(t+V)$ 的滤波器来说很实用，其中 $V$ 和符号决定了功率传递函数的形状，如图 7 所示。该算法基于这样的假设：$V$ 和符号的一些值将使目标信号优于干扰信号，并改进周期性。通过搜索以下函数的最小值来确定参数 $V$、符号和周期 $T$： \(\begin{align} dd_{t}^{'}(\tau, v) &amp;= r_{t}(0) + r_{t+\tau}(0) + r_{t+v}(0) + r_{t+\tau+v}(0) \notag \\ &amp;\pm 2r_{t}(\tau) - 2r_{t}(v) \mp 2r_{t}(\tau+v) \notag \\ &amp;\mp2r_{t+\tau}(v - \tau) - 2r_{t+\tau}(v) \pm 2r_{t+v}(\tau), \end{align}\)</p> <p>$T$ 和 $V$ 的搜索空间应该是不相交的，以防止调谐到 $V$ 的梳状滤波器干扰 $T$ 的估计。同样，该模型也更加宽松。</p> <h3 id="f-与目标频谱相同的加性噪声">F. 与目标频谱相同的加性噪声</h3> <p>如果加性噪声在某个时刻与目标的谱包络相同，则先前的方法都无效。如果目标是稳态的并且持续时间足够长，那么仍然可以提高可靠性和准确性。想法是在给定可用数据的情况下，尽可能多地进行周期比较。令 $D$ 表示持续时间，并将窗口大小 $W$ 设置为至少与最大预期周期一样大，计算以下函数： \(\begin{align} d_{k}(\tau) = \sum_{j=1}^{D-kW}(x_{j}-x_{j-\tau})^{2}, \quad k=1,\cdots,D/W. \end{align}\)</p> <p>接着计算： \(\begin{align} d(\tau) = \sum_{k=1}^{D/W}d_{k}(\tau/(D/W-k)). \end{align}\)</p> <p>该函数是 $(D/W)(D/W21)/2$ 个差值之和。当 $\tau \neq T$ 时，每个差值包含一个确定的部分（目标）和噪声部分，当 $\tau = T$ 时，只包含噪声部分。确定性部分同相相加，而噪声部分往往相互抵消，$\tau = T$ 处下降的显著性得到增强。</p> <p>总的来说，可以对基础模型通过多种方式扩展来处理特定形式的非周期性。在某些情况下，可以将这些扩展进行组合。尽管尚未探索所有组合，不过可以将该灵活性视为该方法的一个有用特征。</p> <h2 id="9-与听觉感知模型的关系">9. 与听觉感知模型的关系</h2> <p>正如第 3 章中所指出的那样，自相关模型是音调感知的一种流行解释，将该模型转变为准确的语音 $F0$ 估计方法的尝试取得了一定的成功。 这项研究展示了如何做到这一点。先前的一项研究表明，兴奋性巧合可以被抑制性“反巧合”所取代，从而产生在许多方面相当于自相关的“音调感知消除模型”。 目前的研究发现，消除实际上更有效，而且它可以准确地实现为自相关项的总和。</p> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/paper_yin/%E5%9B%BE8-480.webp 480w,/assets/img/paper_yin/%E5%9B%BE8-800.webp 800w,/assets/img/paper_yin/%E5%9B%BE8-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/assets/img/paper_yin/%E5%9B%BE8.png" class="img-fluid rounded" width="100%" height="auto" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <p>消除模型需要具有快速时间特性的兴奋性和抑制性突触。本项研究表明，仅使用快速兴奋性突触就可以获得相同的功能，如图 8 所示。有证据表明听觉系统中存在快速兴奋性相互作用，例如在 medial superior olive（MSO）内，以及快速抑制相互作用，例如在 lateral superior olive（LSO）内，其由来自耳蜗核的兴奋性输入和来自内侧梯形体的抑制性输入供给。然而，抑制性相互作用的时间准确性限制可能低于兴奋性相互作用。</p> <p>上一章节展示了如何将一系列减法运算重新表述为自相关项之和。转移到神经领域，这表明 de Cheveigne´ 和 Kawahara 提出的级联消除阶段可以解释多种音高感知，或 de Cheveigne´ 为了考虑并发元音识别，可以在单个阶段中实现为等式 $(15)$ 或 $(16)$ 的神经等价物。取消级联时域处理可以避免一系列锁相神经元的假设，从而使此类模型更加合理。 类似的评论也适用于双耳处理的消除模型。</p> <p>总而言之，信号处理和听觉感知之间可以得出有用的相似之处。 YIN 算法实际上是听觉模型工作的副产品。 相反，解决这个实际任务可能对听觉建模有益，因为它揭示了建模研究中不明显但听觉过程面临的困难。</p> <h2 id="10-讨论">10. 讨论</h2> <p>研究者们已经提出了数百种 $F0$ 估计方法，其中许多方法巧妙而复杂。 它们的数学基础通常假设周期性，而当周期性降低时，它们可能会以难以预测的方式崩溃。正如第 4 章 A 节所指出的，看似不同的估计方法是相关的，并且我们对误差机制的分析可能可以在经过必要的修改后转用到更广泛的方法中。 特别是，每种方法都面临着权衡过高与过低错误的问题。YIN 成功的关键可能是步骤 3，可以让它独立解决这两类错误。 其它步骤可以视为为此步骤做准备（步骤 1 和 2）或在此步骤的基础上进行构建（步骤 4 和 6）。抛物线插值（步骤 5）给出子样本分辨率。使用不大的信号间隔可以获得非常准确的估计。 准确地说，为了准确估计完美周期信号的周期 $T$，并确保真实周期不会大于 $T$，至少需要 $2T+1$ 个数据样本。 如果这一点被认可，理论上精度就没有限制。 特别是，它不受熟悉的不确定性原理 $\triangle T \triangle F = \text{const}$ 的限制。</p> <p>我们避免使用熟悉的后处理方案，例如中值平滑或动态规划，因为包含它们会使评估和信用分配变得复杂。 没有什么可以阻止应用它们来进一步提高该方法的稳健性。 非周期性测量 $d^{‘}(T)$ 可用于确保估计值根据其可靠性而不是连续性本身进行校正。</p> <p>还避免了声音检测的问题，同样是因为它使评估和信用分配变得非常复杂。非周期性测量 $d^{‘}\tau$ 似乎是发声检测的良好基础，也许与能量相结合。 然而，将发声等同于周期性并不令人满意，因为某些形式的发声本质上是不规则的。它们可能仍然带有语调线索，但如何量化它们尚不清楚。在另一篇论文中，我们提出了一种相当不同的 $F0$ 估计和声门事件检测方法，该方法基于瞬时频率以及沿着频率和时间轴的映射中搜索固定点。 这两篇论文共同为 $F0$ 估计的旧任务提供了新的视角。</p> <p>YIN 仅在音乐方面进行过非正式评估，但有理由认为它适合该任务。 音乐特有的困难是 $F0$ 的范围宽且变化快。 YIN 的开放式搜索范围以及在没有连续性约束的情况下表现良好的事实使其比其它算法具有优势。 其它尚未测试的潜在优势包括交互式系统的低延迟或处理复调音乐的扩展。由于要测试的乐器和风格范围广泛，并且缺乏标记良好且具有代表性的数据库，音乐评估变得复杂。</p> <p>有什么新内容？Licklider 提出自相关用于周期性分析，Hess 详细回顾了将其应用于语音的早期尝试，他还追溯了 AMDF 等差分函数方法的起源。Ney 分析了式 $(7)$ 中利用的两者之间的关系。de Cheveigne´ 将步骤 3 和 4 分别应用于 AMDF。 步骤 5 是一项标准技术，例如应用于 Duifhuis 等人的 $F0$ 估计方法中的频谱峰值。 新的是步骤 6，将所描述的步骤组合起来的想法，分析其为何有效，以及最重要的正式评估。</p> <h2 id="11-总结">11. 总结</h2> <p>本文提出了一种用于估计语音或音乐声音的基频的算法。从众所周知的自相关方法开始，引入了许多修改，以避免估计错误。当对与喉镜信号一起记录的语音的广泛数据库进行测试时，错误率比最佳竞争方法小 $3$ 倍，且无需进行后处理。该算法参数很少，不需要微调。与大多数其他方法相比，不需要对 $F0$ 搜索范围设置上限。该方法相对简单并且可以以低延迟有效地实现，并且可以以多种方式扩展以处理在特定应用中出现的多种形式的非周期性。最后，听觉处理模型可以得出一个有趣的相似之处。</p>]]></content><author><name></name></author><category term="论文笔记"/><category term="pitch"/><category term="yin"/><summary type="html"><![CDATA[本文对 Alain de Cheveigne´ 等人于 2002 年在 The Journal of the Acoustical Society of America 上发表的论文进行简单地翻译。如有表述不当之处欢迎批评指正。欢迎任何形式的转载，但请务必注明出处。]]></summary></entry><entry><title type="html">a post with image galleries</title><link href="https://xinleiren.github.io/blog/2024/photo-gallery/" rel="alternate" type="text/html" title="a post with image galleries"/><published>2024-12-04T01:59:00+00:00</published><updated>2024-12-04T01:59:00+00:00</updated><id>https://xinleiren.github.io/blog/2024/photo-gallery</id><content type="html" xml:base="https://xinleiren.github.io/blog/2024/photo-gallery/"><![CDATA[<p>The images in this post are all zoomable, arranged into different mini-galleries using different libraries.</p> <h2 id="lightbox2"><a href="https://lokeshdhakar.com/projects/lightbox2/">Lightbox2</a></h2> <p><a href="https://cdn.photoswipe.com/photoswipe-demo-images/photos/1/img-2500.jpg" data-lightbox="roadtrip"><img src="https://cdn.photoswipe.com/photoswipe-demo-images/photos/1/img-200.jpg"/></a> <a href="https://cdn.photoswipe.com/photoswipe-demo-images/photos/2/img-2500.jpg" data-lightbox="roadtrip"><img src="https://cdn.photoswipe.com/photoswipe-demo-images/photos/2/img-200.jpg"/></a> <a href="https://cdn.photoswipe.com/photoswipe-demo-images/photos/3/img-2500.jpg" data-lightbox="roadtrip"><img src="https://cdn.photoswipe.com/photoswipe-demo-images/photos/3/img-200.jpg"/></a></p> <hr/> <h2 id="photoswipe"><a href="https://photoswipe.com/">PhotoSwipe</a></h2> <div class="pswp-gallery pswp-gallery--single-column" id="gallery--getting-started"> <a href="https://cdn.photoswipe.com/photoswipe-demo-images/photos/2/img-2500.jpg" data-pswp-width="1669" data-pswp-height="2500" target="_blank"> <img src="https://cdn.photoswipe.com/photoswipe-demo-images/photos/2/img-200.jpg" alt=""/> </a> <a href="https://cdn.photoswipe.com/photoswipe-demo-images/photos/7/img-2500.jpg" data-pswp-width="1875" data-pswp-height="2500" data-cropped="true" target="_blank"> <img src="https://cdn.photoswipe.com/photoswipe-demo-images/photos/7/img-200.jpg" alt=""/> </a> <a href="https://unsplash.com" data-pswp-src="https://cdn.photoswipe.com/photoswipe-demo-images/photos/3/img-2500.jpg" data-pswp-width="2500" data-pswp-height="1666" target="_blank"> <img src="https://cdn.photoswipe.com/photoswipe-demo-images/photos/3/img-200.jpg" alt=""/> </a> <div> <a href="https://cdn.photoswipe.com/photoswipe-demo-images/photos/6/img-2500.jpg" data-pswp-width="2500" data-pswp-height="1667" target="_blank"> <img src="https://cdn.photoswipe.com/photoswipe-demo-images/photos/6/img-200.jpg" alt=""/> </a> </div> </div> <hr/> <h2 id="spotlight-js"><a href="https://nextapps-de.github.io/spotlight/">Spotlight JS</a></h2> <div class="spotlight-group"> <a class="spotlight" href="https://cdn.photoswipe.com/photoswipe-demo-images/photos/1/img-2500.jpg"> <img src="https://cdn.photoswipe.com/photoswipe-demo-images/photos/1/img-200.jpg"/> </a> <a class="spotlight" href="https://cdn.photoswipe.com/photoswipe-demo-images/photos/2/img-2500.jpg"> <img src="https://cdn.photoswipe.com/photoswipe-demo-images/photos/2/img-200.jpg"/> </a> <a class="spotlight" href="https://cdn.photoswipe.com/photoswipe-demo-images/photos/3/img-2500.jpg"> <img src="https://cdn.photoswipe.com/photoswipe-demo-images/photos/3/img-200.jpg"/> </a> </div> <div class="spotlight-group"> <a class="spotlight" href="https://cdn.photoswipe.com/photoswipe-demo-images/photos/4/img-2500.jpg"> <img src="https://cdn.photoswipe.com/photoswipe-demo-images/photos/4/img-200.jpg"/> </a> <a class="spotlight" href="https://cdn.photoswipe.com/photoswipe-demo-images/photos/5/img-2500.jpg"> <img src="https://cdn.photoswipe.com/photoswipe-demo-images/photos/5/img-200.jpg"/> </a> <a class="spotlight" href="https://cdn.photoswipe.com/photoswipe-demo-images/photos/6/img-2500.jpg"> <img src="https://cdn.photoswipe.com/photoswipe-demo-images/photos/6/img-200.jpg"/> </a> </div> <hr/> <h2 id="venobox"><a href="https://veno.es/venobox/">Venobox</a></h2> <p><a class="venobox" data-gall="myGallery" href="https://cdn.photoswipe.com/photoswipe-demo-images/photos/1/img-2500.jpg"><img src="https://cdn.photoswipe.com/photoswipe-demo-images/photos/1/img-200.jpg"/></a> <a class="venobox" data-gall="myGallery" href="https://cdn.photoswipe.com/photoswipe-demo-images/photos/2/img-2500.jpg"><img src="https://cdn.photoswipe.com/photoswipe-demo-images/photos/2/img-200.jpg"/></a> <a class="venobox" data-gall="myGallery" href="https://cdn.photoswipe.com/photoswipe-demo-images/photos/3/img-2500.jpg"><img src="https://cdn.photoswipe.com/photoswipe-demo-images/photos/3/img-200.jpg"/></a></p>]]></content><author><name></name></author><category term="sample-posts"/><category term="formatting"/><category term="images"/><summary type="html"><![CDATA[this is what included image galleries could look like]]></summary></entry><entry><title type="html">Google Gemini updates: Flash 1.5, Gemma 2 and Project Astra</title><link href="https://xinleiren.github.io/blog/2024/google-gemini-updates-flash-15-gemma-2-and-project-astra/" rel="alternate" type="text/html" title="Google Gemini updates: Flash 1.5, Gemma 2 and Project Astra"/><published>2024-05-14T00:00:00+00:00</published><updated>2024-05-14T00:00:00+00:00</updated><id>https://xinleiren.github.io/blog/2024/google-gemini-updates-flash-15-gemma-2-and-project-astra</id><content type="html" xml:base="https://xinleiren.github.io/blog/2024/google-gemini-updates-flash-15-gemma-2-and-project-astra/"><![CDATA[]]></content><author><name></name></author><summary type="html"><![CDATA[We’re sharing updates across our Gemini family of models and a glimpse of Project Astra, our vision for the future of AI assistants.]]></summary></entry><entry><title type="html">a post with tabs</title><link href="https://xinleiren.github.io/blog/2024/tabs/" rel="alternate" type="text/html" title="a post with tabs"/><published>2024-05-01T00:32:13+00:00</published><updated>2024-05-01T00:32:13+00:00</updated><id>https://xinleiren.github.io/blog/2024/tabs</id><content type="html" xml:base="https://xinleiren.github.io/blog/2024/tabs/"><![CDATA[<p>This is how a post with <a href="https://github.com/Ovski4/jekyll-tabs">tabs</a> looks like. Note that the tabs could be used for different purposes, not only for code.</p> <h2 id="first-tabs">First tabs</h2> <p>To add tabs, use the following syntax:</p> <div class="language-liquid highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="cp">{%</span><span class="w"> </span><span class="nt">tabs</span><span class="w"> </span><span class="nv">group-name</span><span class="w"> </span><span class="cp">%}</span>

<span class="cp">{%</span><span class="w"> </span><span class="nt">tab</span><span class="w"> </span><span class="nv">group-name</span><span class="w"> </span><span class="nv">tab-name-1</span><span class="w"> </span><span class="cp">%}</span>

Content 1

<span class="cp">{%</span><span class="w"> </span><span class="nt">endtab</span><span class="w"> </span><span class="cp">%}</span>

<span class="cp">{%</span><span class="w"> </span><span class="nt">tab</span><span class="w"> </span><span class="nv">group-name</span><span class="w"> </span><span class="nv">tab-name-2</span><span class="w"> </span><span class="cp">%}</span>

Content 2

<span class="cp">{%</span><span class="w"> </span><span class="nt">endtab</span><span class="w"> </span><span class="cp">%}</span>

<span class="cp">{%</span><span class="w"> </span><span class="nt">endtabs</span><span class="w"> </span><span class="cp">%}</span>
</code></pre></div></div> <p>With this you can generate visualizations like:</p> <ul id="log" class="tab" data-tab="c941287f-73d7-4158-851a-869a311d2892" data-name="log"> <li class="active" id="log-php"> <a href="#">php </a> </li> <li id="log-js"> <a href="#">js </a> </li> <li id="log-ruby"> <a href="#">ruby </a> </li> </ul> <ul class="tab-content" id="c941287f-73d7-4158-851a-869a311d2892" data-name="log"> <li class="active"> <div class="language-php highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nb">var_dump</span><span class="p">(</span><span class="s1">'hello'</span><span class="p">);</span>
</code></pre></div></div> </li> <li> <div class="language-javascript highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nx">console</span><span class="p">.</span><span class="nf">log</span><span class="p">(</span><span class="dl">"</span><span class="s2">hello</span><span class="dl">"</span><span class="p">);</span>
</code></pre></div></div> </li> <li> <div class="language-javascript highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nx">pputs</span> <span class="dl">'</span><span class="s1">hello</span><span class="dl">'</span>
</code></pre></div></div> </li> </ul> <h2 id="another-example">Another example</h2> <ul id="data-struct" class="tab" data-tab="0f5b4339-7555-450e-adfc-5a515fa9e8df" data-name="data-struct"> <li class="active" id="data-struct-yaml"> <a href="#">yaml </a> </li> <li id="data-struct-json"> <a href="#">json </a> </li> </ul> <ul class="tab-content" id="0f5b4339-7555-450e-adfc-5a515fa9e8df" data-name="data-struct"> <li class="active"> <div class="language-yaml highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="na">hello</span><span class="pi">:</span>
  <span class="pi">-</span> <span class="s2">"</span><span class="s">whatsup"</span>
  <span class="pi">-</span> <span class="s2">"</span><span class="s">hi"</span>
</code></pre></div></div> </li> <li> <div class="language-json highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="p">{</span><span class="w">
  </span><span class="nl">"hello"</span><span class="p">:</span><span class="w"> </span><span class="p">[</span><span class="s2">"whatsup"</span><span class="p">,</span><span class="w"> </span><span class="s2">"hi"</span><span class="p">]</span><span class="w">
</span><span class="p">}</span><span class="w">
</span></code></pre></div></div> </li> </ul> <h2 id="tabs-for-something-else">Tabs for something else</h2> <ul id="something-else" class="tab" data-tab="82f59132-1a19-4092-8bd0-fcae2facb9e0" data-name="something-else"> <li class="active" id="something-else-text"> <a href="#">text </a> </li> <li id="something-else-quote"> <a href="#">quote </a> </li> <li id="something-else-list"> <a href="#">list </a> </li> </ul> <ul class="tab-content" id="82f59132-1a19-4092-8bd0-fcae2facb9e0" data-name="something-else"> <li class="active"> <p>Regular text</p> </li> <li> <blockquote> <p>A quote</p> </blockquote> </li> <li> <p>Hipster list</p> <ul> <li>brunch</li> <li>fixie</li> <li>raybans</li> <li>messenger bag</li> </ul> </li> </ul>]]></content><author><name></name></author><category term="sample-posts"/><category term="formatting"/><category term="code"/><summary type="html"><![CDATA[this is what included tabs in a post could look like]]></summary></entry><entry><title type="html">a post with typograms</title><link href="https://xinleiren.github.io/blog/2024/typograms/" rel="alternate" type="text/html" title="a post with typograms"/><published>2024-04-29T23:36:10+00:00</published><updated>2024-04-29T23:36:10+00:00</updated><id>https://xinleiren.github.io/blog/2024/typograms</id><content type="html" xml:base="https://xinleiren.github.io/blog/2024/typograms/"><![CDATA[<p>This is an example post with some <a href="https://github.com/google/typograms/">typograms</a> code.</p> <div class="language-markdown highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="p">```</span><span class="nl">typograms
</span><span class="sb">+----+
|    |---&gt; My first diagram!
+----+</span>
<span class="p">```</span>
</code></pre></div></div> <p>Which generates:</p> <pre><code class="language-typograms">+----+
|    |---&gt; My first diagram!
+----+
</code></pre> <p>Another example:</p> <div class="language-markdown highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="p">```</span><span class="nl">typograms
</span><span class="sb">.------------------------.
|.----------------------.|
||"https://example.com" ||
|'----------------------'|
| ______________________ |
||                      ||
||   Welcome!           ||
||                      ||
||                      ||
||  .----------------.  ||
||  | username       |  ||
||  '----------------'  ||
||  .----------------.  ||
||  |"*******"       |  ||
||  '----------------'  ||
||                      ||
||  .----------------.  ||
||  |   "Sign-up"    |  ||
||  '----------------'  ||
||                      ||
|+----------------------+|
.------------------------.</span>
<span class="p">```</span>
</code></pre></div></div> <p>which generates:</p> <pre><code class="language-typograms">.------------------------.
|.----------------------.|
||"https://example.com" ||
|'----------------------'|
| ______________________ |
||                      ||
||   Welcome!           ||
||                      ||
||                      ||
||  .----------------.  ||
||  | username       |  ||
||  '----------------'  ||
||  .----------------.  ||
||  |"*******"       |  ||
||  '----------------'  ||
||                      ||
||  .----------------.  ||
||  |   "Sign-up"    |  ||
||  '----------------'  ||
||                      ||
|+----------------------+|
.------------------------.
</code></pre> <p>For more examples, check out the <a href="https://google.github.io/typograms/#examples">typograms documentation</a>.</p>]]></content><author><name></name></author><category term="sample-posts"/><category term="formatting"/><category term="diagrams"/><summary type="html"><![CDATA[this is what included typograms code could look like]]></summary></entry></feed>